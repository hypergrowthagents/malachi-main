Source: [https://substack.com/app-link/post?publication_id=10845&post_id=175221480&utm_source=post-email-title&utm_campaign=email-post-title&isFreemail=false&r=ova8r&token=eyJ1c2VyX2lkIjo0MTc3MDM5NSwicG9zdF9pZCI6MTc1MjIxNDgwLCJpYXQiOjE3NjAxOTkzMjQsImV4cCI6MTc2Mjc5MTMyNCwiaXNzIjoicHViLTEwODQ1Iiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.7qt1hDqbu04lteglOrjywOlhfJyKSSPY3Zxe2_zVKCM](https://substack.com/app-link/post?publication_id=10845&post_id=175221480&utm_source=post-email-title&utm_campaign=email-post-title&isFreemail=false&r=ova8r&token=eyJ1c2VyX2lkIjo0MTc3MDM5NSwicG9zdF9pZCI6MTc1MjIxNDgwLCJpYXQiOjE3NjAxOTkzMjQsImV4cCI6MTc2Mjc5MTMyNCwiaXNzIjoicHViLTEwODQ1Iiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.7qt1hDqbu04lteglOrjywOlhfJyKSSPY3Zxe2_zVKCM)
### Getting better at AI

> **Q: After 6 months training senior executives to be “AI Ready in 180,” I asked Gemini to analyze my entire program folder independently. The AI’s findings validated what I see work repeatedly—not what vendors promise, but what actually helps executives deliver results:**
> 
> **1. Context beats everything**
> 
> **Generic prompts = generic results.** The executives who succeed upload their actual documents, build rich knowledge bases, and give AI the context it needs to understand their specific industry and challenges.
> 
> **2. Master 2 tools, not 20**
> 
> **Every week there’s a new AI tool.** My most successful participants pick ChatGPT + one other (usually Claude or Perplexity) and go deep. Depth beats breadth.
> 
> **3. Never accept the first draft**
> 
> **The magic question:** “What would make this world-class?” Teaching executives to iterate, not just prompt, transforms their outputs from mediocre to exceptional.
> 
> **4. Projects > prompts**
> 
> **Stop having random AI conversations.** Organize into projects with persistent context, uploaded files, and consistent instructions. This structure drives consistency.
> 
> **5. Ethics aren’t optional**
> 
> **Banking compliance, GDPR, data privacy**—build it into every workflow from day 1. The executives who succeed long-term are the ones who automate responsibly.
> 
> **6. Continuous experimentation**
> 
> **The program emphasizes ongoing learning.** AI capability isn’t a destination but a journey of continuous development and adaptation as technology evolves.
> 
> **7. 180 minutes changes trajectory**
> 
> **Two 90-minute sessions.** That’s what it takes to go from AI-curious to AI-capable. Not because AI is simple, but because focused implementation beats endless exploration. [↗️](https://substack.com/redirect/0368f373-4a7e-43e1-ad43-187dc655b1b4?j=eyJ1Ijoib3ZhOHIifQ.TgwQtBGOYM9uTaI2ohA3I1FnogmdOhp2hXanmf7Ccl0)
> 
> **—[Kim Siler](https://substack.com/redirect/9a652066-5f45-4b71-9ef5-ac5b83d9eb37?j=eyJ1Ijoib3ZhOHIifQ.TgwQtBGOYM9uTaI2ohA3I1FnogmdOhp2hXanmf7Ccl0)**

**Tolga**: What would you cover in the 90-minute sessions?

**Kim**: Hey [@Tolga](https://substack.com/redirect/96be2313-3159-4580-bf61-9eead3ea033c?j=eyJ1Ijoib3ZhOHIifQ.TgwQtBGOYM9uTaI2ohA3I1FnogmdOhp2hXanmf7Ccl0)! Here’s the breakdown:

**Session 1: Foundations & First Build (90 min)**

- First 25 min: Core concepts (LLMs vs. agents vs. custom GPTs), which tool for what, avoiding hallucinations
    
- Next 40 min: Hands-on build of _your_ specific use case—we build an actual working system using your real work scenarios
    
- Final 25 min: Testing, refining prompts, setting up for the week ahead
    

**Session 2: Scale & Automate (90 min)**

- First 10 min: Debug what you built during the week
    
- Next 45 min: Advanced integration—scheduling, multi-step workflows, connecting tools
    
- Final 35 min: Building your 30-day implementation roadmap
    

The magic is that it’s 100% hands-on with _your_ actual work. You leave Session 1 with something that works. You leave Session 2 knowing how to scale it.

No theory without practice. No generic examples—we use your real challenges.

What specific work task would you want to automate if you joined?

**[Sid Wiesner](https://substack.com/redirect/4155a607-d77c-4347-88d3-8afcc582d663?j=eyJ1Ijoib3ZhOHIifQ.TgwQtBGOYM9uTaI2ohA3I1FnogmdOhp2hXanmf7Ccl0)**: Great takeaways—1-6 resonate a lot. Were these 2 sessions 1x1 deep dives, or were you able to do these hands-on builds in group settings? I’ve mostly been doing group sessions for functional areas, and think that’s working, but you’re raising some good ideas here about how far to go to personalize.

Also, if you’re comfortable sharing, would love to hear any other details about session 2 and the advanced integration work.

In those group sessions, I’ve found it really useful to do some demos first using some realistic use cases. I think it helps break the ice on what AI is and how it could be useful to me. I also agree on context + projects, but realize some people get stuck figuring out prompts, so I’ve often built a first version of some prompts to share with them to get them thinking about it, and I find that the prompts unlock some aha moments, even for people already using AI tools in their day-to-day.

**Kim:** I keep groups at 3-5 too—that’s the sweet spot. The cross-pollination between different industries is actually the secret sauce. A banker’s compliance question unlocks something for the marketer. The technical founder gives the non-technical CEO permission to experiment.

The mixed backgrounds also create psychological safety—when senior execs see peers asking “basic” questions, everyone relaxes and actually learns.

Session 2 is about scaling what worked—adding automation, connecting tools, building templates. The confidence to iterate matters more than the specific tech.

Seeing ops/finance folks adopt faster than expected—they already think in processes. You?

Hmm ... maybe I need to create a LinkedIn post about _those_ insights. LOL

**Sid Wiesner:** I’m seeing similar, and also high adoption from engineering managers too. I’m in the nonprofit space, so any role with a lot of research or writing seems to gravitate quickly to it, but more piecemeal and they definitely could benefit from better practices, especially the points in your original message. For example, I see them often doing 1-shot prompts, and they get what I would deem as fairly average responses.

**Sesh:** I like the agenda and it mirrors very closely the approach I have taken/am taking. The key thing is to get hands on keyboard; nothing demonstrates reality better than actual experience. I’d add a section on which LLM does what better/best, as each LLM does have its specific strengths. Definitely with you on the “master 2 tools” and, more important, master the concepts and ideas and you can make any tool do wonders for you.

Nicely done and thanks a lot for sharing with us, [@Kim](https://substack.com/redirect/4a523af2-5aef-488b-b9ad-63c08357f605?j=eyJ1Ijoib3ZhOHIifQ.TgwQtBGOYM9uTaI2ohA3I1FnogmdOhp2hXanmf7Ccl0)